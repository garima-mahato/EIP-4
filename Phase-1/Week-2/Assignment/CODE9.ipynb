{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MyCode9.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztUmGfNSBZg2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Activation, GlobalAveragePooling2D, BatchNormalization, Dropout\n",
        "from keras.datasets import mnist \n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqsIVvxckRoG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6ca67a7b-a388-461a-f9a8-e9fc740b346d"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwYH76O2H-Au",
        "colab_type": "text"
      },
      "source": [
        "### For Total number of trainable params < 15K\n",
        "----"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIaq8R0vkuHZ",
        "colab_type": "code",
        "outputId": "47f0d42a-bfb7-4ede-ed9a-13db2964622a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(16, 3, use_bias=False, input_shape=(28,28,1), activation='relu')) #26\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Conv2D(32, 3, use_bias=False, activation='relu')) #24\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) #12\n",
        "\n",
        "\n",
        "model.add(Conv2D(16, 1, use_bias=False, activation='relu')) #12\n",
        "\n",
        "model.add(Conv2D(16, 3, use_bias=False, activation='relu')) #10\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Conv2D(16, 3, use_bias=False, activation='relu')) #8\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Conv2D(16, 3, use_bias=False, activation='relu')) #6\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Conv2D(16, 3, use_bias=False, activation='relu')) #4\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(10, 1, use_bias=False, activation='relu'))\n",
        "\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_77 (Conv2D)           (None, 26, 26, 16)        144       \n",
            "_________________________________________________________________\n",
            "batch_normalization_30 (Batc (None, 26, 26, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_78 (Conv2D)           (None, 24, 24, 32)        4608      \n",
            "_________________________________________________________________\n",
            "batch_normalization_31 (Batc (None, 24, 24, 32)        128       \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_79 (Conv2D)           (None, 12, 12, 16)        512       \n",
            "_________________________________________________________________\n",
            "conv2d_80 (Conv2D)           (None, 10, 10, 16)        2304      \n",
            "_________________________________________________________________\n",
            "batch_normalization_32 (Batc (None, 10, 10, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 10, 10, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_81 (Conv2D)           (None, 8, 8, 16)          2304      \n",
            "_________________________________________________________________\n",
            "batch_normalization_33 (Batc (None, 8, 8, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_82 (Conv2D)           (None, 6, 6, 16)          2304      \n",
            "_________________________________________________________________\n",
            "batch_normalization_34 (Batc (None, 6, 6, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_29 (Dropout)         (None, 6, 6, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_83 (Conv2D)           (None, 4, 4, 16)          2304      \n",
            "_________________________________________________________________\n",
            "batch_normalization_35 (Batc (None, 4, 4, 16)          64        \n",
            "_________________________________________________________________\n",
            "conv2d_84 (Conv2D)           (None, 4, 4, 10)          160       \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_12  (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 15,088\n",
            "Trainable params: 14,864\n",
            "Non-trainable params: 224\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFWdUWOsmWji",
        "colab_type": "code",
        "outputId": "f84921c9-9ae6-4f72-890a-dff118bae550",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1, validation_data=(X_test, Y_test), callbacks=[LearningRateScheduler(scheduler, verbose=1)])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "60000/60000 [==============================] - 10s 175us/step - loss: 0.2587 - acc: 0.9335 - val_loss: 0.0700 - val_acc: 0.9793\n",
            "Epoch 2/20\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "60000/60000 [==============================] - 6s 102us/step - loss: 0.0592 - acc: 0.9824 - val_loss: 0.0391 - val_acc: 0.9881\n",
            "Epoch 3/20\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "60000/60000 [==============================] - 6s 102us/step - loss: 0.0454 - acc: 0.9864 - val_loss: 0.0349 - val_acc: 0.9895\n",
            "Epoch 4/20\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "60000/60000 [==============================] - 6s 102us/step - loss: 0.0378 - acc: 0.9884 - val_loss: 0.0319 - val_acc: 0.9903\n",
            "Epoch 5/20\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 0.0337 - acc: 0.9894 - val_loss: 0.0270 - val_acc: 0.9909\n",
            "Epoch 6/20\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 0.0299 - acc: 0.9909 - val_loss: 0.0204 - val_acc: 0.9937\n",
            "Epoch 7/20\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0267 - acc: 0.9919 - val_loss: 0.0243 - val_acc: 0.9916\n",
            "Epoch 8/20\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0267 - acc: 0.9920 - val_loss: 0.0216 - val_acc: 0.9936\n",
            "Epoch 9/20\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "60000/60000 [==============================] - 6s 102us/step - loss: 0.0233 - acc: 0.9929 - val_loss: 0.0191 - val_acc: 0.9940\n",
            "Epoch 10/20\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "60000/60000 [==============================] - 6s 101us/step - loss: 0.0216 - acc: 0.9931 - val_loss: 0.0226 - val_acc: 0.9921\n",
            "Epoch 11/20\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 0.0209 - acc: 0.9935 - val_loss: 0.0225 - val_acc: 0.9925\n",
            "Epoch 12/20\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "60000/60000 [==============================] - 6s 101us/step - loss: 0.0203 - acc: 0.9936 - val_loss: 0.0195 - val_acc: 0.9933\n",
            "Epoch 13/20\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 0.0188 - acc: 0.9941 - val_loss: 0.0199 - val_acc: 0.9937\n",
            "Epoch 14/20\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 0.0174 - acc: 0.9944 - val_loss: 0.0174 - val_acc: 0.9942\n",
            "Epoch 15/20\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 0.0174 - acc: 0.9945 - val_loss: 0.0163 - val_acc: 0.9942\n",
            "Epoch 16/20\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 0.0162 - acc: 0.9948 - val_loss: 0.0179 - val_acc: 0.9942\n",
            "Epoch 17/20\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "60000/60000 [==============================] - 6s 102us/step - loss: 0.0160 - acc: 0.9950 - val_loss: 0.0169 - val_acc: 0.9943\n",
            "Epoch 18/20\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "60000/60000 [==============================] - 6s 101us/step - loss: 0.0164 - acc: 0.9949 - val_loss: 0.0191 - val_acc: 0.9942\n",
            "Epoch 19/20\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "60000/60000 [==============================] - 6s 99us/step - loss: 0.0148 - acc: 0.9954 - val_loss: 0.0183 - val_acc: 0.9942\n",
            "Epoch 20/20\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "60000/60000 [==============================] - 6s 99us/step - loss: 0.0152 - acc: 0.9952 - val_loss: 0.0182 - val_acc: 0.9947\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7d82595710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xr5_DqKnmssH",
        "colab_type": "code",
        "outputId": "86fa10aa-39ff-42ba-e998-ae7fc90ece6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(score)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.01818742549381859, 0.9947]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXKQPTbPHm3n",
        "colab_type": "text"
      },
      "source": [
        "### For Total number of params < 15K (final model and training)\n",
        "----\n",
        "\n",
        "Since the Total number of parameters exceeded 15K, I dropped batch normalisation and then trained the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cq5zU9Gc9lIs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "outputId": "23f812f4-4ef3-4e12-f8c6-fa3181bb3947"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(16, 3, use_bias=False, input_shape=(28,28,1), activation='relu')) #26\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Conv2D(32, 3, use_bias=False, activation='relu')) #24\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) #12\n",
        "\n",
        "\n",
        "model.add(Conv2D(16, 1, use_bias=False, activation='relu')) #12\n",
        "\n",
        "model.add(Conv2D(16, 3, use_bias=False, activation='relu')) #10\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Conv2D(16, 3, use_bias=False, activation='relu')) #8\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Conv2D(16, 3, use_bias=False, activation='relu')) #6\n",
        "#model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Conv2D(16, 3, use_bias=False, activation='relu')) #4\n",
        "\n",
        "model.add(Conv2D(10, 1, use_bias=False, activation='relu'))\n",
        "\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_101 (Conv2D)          (None, 26, 26, 16)        144       \n",
            "_________________________________________________________________\n",
            "batch_normalization_45 (Batc (None, 26, 26, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_39 (Dropout)         (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_102 (Conv2D)          (None, 24, 24, 32)        4608      \n",
            "_________________________________________________________________\n",
            "batch_normalization_46 (Batc (None, 24, 24, 32)        128       \n",
            "_________________________________________________________________\n",
            "dropout_40 (Dropout)         (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_103 (Conv2D)          (None, 12, 12, 16)        512       \n",
            "_________________________________________________________________\n",
            "conv2d_104 (Conv2D)          (None, 10, 10, 16)        2304      \n",
            "_________________________________________________________________\n",
            "batch_normalization_47 (Batc (None, 10, 10, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_41 (Dropout)         (None, 10, 10, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_105 (Conv2D)          (None, 8, 8, 16)          2304      \n",
            "_________________________________________________________________\n",
            "batch_normalization_48 (Batc (None, 8, 8, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_42 (Dropout)         (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_106 (Conv2D)          (None, 6, 6, 16)          2304      \n",
            "_________________________________________________________________\n",
            "dropout_43 (Dropout)         (None, 6, 6, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_107 (Conv2D)          (None, 4, 4, 16)          2304      \n",
            "_________________________________________________________________\n",
            "conv2d_108 (Conv2D)          (None, 4, 4, 10)          160       \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_15  (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 14,960\n",
            "Trainable params: 14,800\n",
            "Non-trainable params: 160\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMZLH1tW920W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "17501f00-77c1-4667-92b1-042c09b941f3"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1, validation_data=(X_test, Y_test), callbacks=[LearningRateScheduler(scheduler, verbose=1)])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "60000/60000 [==============================] - 11s 178us/step - loss: 0.2443 - acc: 0.9218 - val_loss: 0.0592 - val_acc: 0.9808\n",
            "Epoch 2/20\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.0571 - acc: 0.9821 - val_loss: 0.0359 - val_acc: 0.9890\n",
            "Epoch 3/20\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "60000/60000 [==============================] - 5s 88us/step - loss: 0.0430 - acc: 0.9865 - val_loss: 0.0276 - val_acc: 0.9902\n",
            "Epoch 4/20\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "60000/60000 [==============================] - 5s 88us/step - loss: 0.0368 - acc: 0.9884 - val_loss: 0.0233 - val_acc: 0.9930\n",
            "Epoch 5/20\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "60000/60000 [==============================] - 5s 87us/step - loss: 0.0336 - acc: 0.9893 - val_loss: 0.0319 - val_acc: 0.9900\n",
            "Epoch 6/20\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "60000/60000 [==============================] - 5s 87us/step - loss: 0.0288 - acc: 0.9911 - val_loss: 0.0248 - val_acc: 0.9921\n",
            "Epoch 7/20\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "60000/60000 [==============================] - 5s 88us/step - loss: 0.0256 - acc: 0.9921 - val_loss: 0.0211 - val_acc: 0.9934\n",
            "Epoch 8/20\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.0246 - acc: 0.9925 - val_loss: 0.0199 - val_acc: 0.9942\n",
            "Epoch 9/20\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "60000/60000 [==============================] - 5s 87us/step - loss: 0.0234 - acc: 0.9930 - val_loss: 0.0202 - val_acc: 0.9945\n",
            "Epoch 10/20\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "60000/60000 [==============================] - 5s 90us/step - loss: 0.0225 - acc: 0.9933 - val_loss: 0.0218 - val_acc: 0.9934\n",
            "Epoch 11/20\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "60000/60000 [==============================] - 5s 90us/step - loss: 0.0200 - acc: 0.9940 - val_loss: 0.0244 - val_acc: 0.9922\n",
            "Epoch 12/20\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "60000/60000 [==============================] - 5s 91us/step - loss: 0.0194 - acc: 0.9940 - val_loss: 0.0180 - val_acc: 0.9942\n",
            "Epoch 13/20\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "60000/60000 [==============================] - 5s 88us/step - loss: 0.0191 - acc: 0.9938 - val_loss: 0.0184 - val_acc: 0.9944\n",
            "Epoch 14/20\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.0179 - acc: 0.9943 - val_loss: 0.0215 - val_acc: 0.9942\n",
            "Epoch 15/20\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.0173 - acc: 0.9944 - val_loss: 0.0197 - val_acc: 0.9943\n",
            "Epoch 16/20\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "60000/60000 [==============================] - 5s 88us/step - loss: 0.0179 - acc: 0.9943 - val_loss: 0.0176 - val_acc: 0.9949\n",
            "Epoch 17/20\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "60000/60000 [==============================] - 5s 87us/step - loss: 0.0147 - acc: 0.9951 - val_loss: 0.0208 - val_acc: 0.9939\n",
            "Epoch 18/20\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.0154 - acc: 0.9951 - val_loss: 0.0192 - val_acc: 0.9941\n",
            "Epoch 19/20\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.0154 - acc: 0.9950 - val_loss: 0.0208 - val_acc: 0.9938\n",
            "Epoch 20/20\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "60000/60000 [==============================] - 5s 88us/step - loss: 0.0144 - acc: 0.9954 - val_loss: 0.0201 - val_acc: 0.9951\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7d81ddc4a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RdMDKVu-C9s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "94b42efa-64e6-4b02-c238-80c196c73db0"
      },
      "source": [
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(score)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.020135334616147155, 0.9951]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}